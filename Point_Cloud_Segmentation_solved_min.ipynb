{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Point_Cloud_Segmentation.solved.min.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ9yp_5yyu3J"
      },
      "outputs": [],
      "source": [
        "# Multi Layer Perceptron\n",
        "class MLP(nn.Module):\n",
        "   def __init__(self, input_size, output_size):\n",
        "     super().__init__()\n",
        "     self.input_size   = input_size\n",
        "     self.output_size  = output_size\n",
        "     self.conv  = nn.Conv1d(self.input_size, self.output_size, 1)\n",
        "     self.bn    = nn.BatchNorm1d(self.output_size)\n",
        "\n",
        "   def forward(self, input):\n",
        "     return F.relu(self.bn(self.conv(input)))\n",
        "\n",
        "# Fully Connected with Batch Normalization\n",
        "class FC_BN(nn.Module):\n",
        "   def __init__(self, input_size, output_size):\n",
        "     super().__init__()\n",
        "     self.input_size   = input_size\n",
        "     self.output_size  = output_size\n",
        "     self.lin  = nn.Linear(self.input_size, self.output_size)\n",
        "     self.bn    = nn.BatchNorm1d(self.output_size)\n",
        "\n",
        "   def forward(self, input):\n",
        "     return F.relu(self.bn(self.lin(input)))\n",
        "\n",
        "class TNet(nn.Module):\n",
        "   def __init__(self, k=3):\n",
        "      super().__init__()\n",
        "      self.k=k\n",
        "\n",
        "      self.mlp1 = MLP(self.k, 64)\n",
        "      self.mlp2 = MLP(64, 128)\n",
        "      self.mlp3 = MLP(128, 1024)\n",
        "\n",
        "      self.fc_bn1 = FC_BN(1024, 512)\n",
        "      self.fc_bn2 = FC_BN(512,256)\n",
        "\n",
        "      self.fc3 = nn.Linear(256,k*k)\n",
        "    \n",
        "\n",
        "   def forward(self, input):\n",
        "      # input.shape == (batch_size,n,3)\n",
        "      \n",
        "      bs = input.size(0)\n",
        "      xb = self.mlp1(input)\n",
        "      xb = self.mlp2(xb)\n",
        "      xb = self.mlp3(xb)\n",
        "\n",
        "      pool = nn.MaxPool1d(xb.size(-1))(xb)\n",
        "      flat = nn.Flatten(1)(pool)\n",
        "\n",
        "      xb = self.fc_bn1(flat)\n",
        "      xb = self.fc_bn2(xb)\n",
        "      \n",
        "      # initialize as identity\n",
        "      init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n",
        "      if xb.is_cuda:\n",
        "        init=init.cuda()\n",
        "      matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n",
        "      return matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNet(nn.Module):\n",
        "   def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_transform = TNet(k=3)\n",
        "\n",
        "        ###########################################################\n",
        "        ################## INSERT YOUR CODE HERE ##################\n",
        "        ###########################################################\n",
        "        self.mlp_64_1 = MLP(3, 64)\n",
        "        self.mlp_64_2 = MLP(64, 64)\n",
        "        self.feature_transform = TNet(k=64)\n",
        "\n",
        "        self.mlp_128 = MLP(64, 128)\n",
        "        self.mlp_1024 = MLP(128, 1024)\n",
        "\n",
        "   def forward(self, input):\n",
        "        n_pts = input.size()[2]\n",
        "        matrix3x3 = self.input_transform(input)\n",
        "        input_transform_output = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n",
        "\n",
        "        ###########################################################\n",
        "        ################## INSERT YOUR CODE HERE ##################\n",
        "        ###########################################################\n",
        "        mlp_1_res = self.mlp_64_1(input_transform_output)\n",
        "        mlp_2_res = self.mlp_64_2(mlp_1_res)\n",
        "        matrix64x64 = self.feature_transform(mlp_2_res)\n",
        "        feature_transform_output = torch.bmm(torch.transpose(mlp_2_res,1,2), matrix64x64).transpose(1,2)\n",
        "        \n",
        "        feature_extraction = self.mlp_1024(self.mlp_128(feature_transform_output))\n",
        "\n",
        "        global_feature = nn.MaxPool1d(feature_extraction.size(-1))(feature_extraction)\n",
        "\n",
        "        global_feature_repeated = nn.Flatten(1)(global_feature).repeat(n_pts,1,1).transpose(0,2).transpose(0,1)\n",
        "\n",
        "        return [feature_transform_output, global_feature_repeated], matrix3x3, matrix64x64\n"
      ],
      "metadata": {
        "id": "dz3_aI2My94c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PointNetSeg(nn.Module):\n",
        "    def __init__(self, classes = 3):\n",
        "        super().__init__()\n",
        "        self.pointnet = PointNet()\n",
        "\n",
        "        ###########################################################\n",
        "        ################## INSERT YOUR CODE HERE ##################\n",
        "        ###########################################################\n",
        "        self.mlp_512_r = MLP(1088, 512)\n",
        "        self.mlp_256_r = MLP(512, 256)\n",
        "        self.mlp_128_r = MLP(256, 128)\n",
        "        self.mlp_3_r = MLP(128, 3)\n",
        "\n",
        "        self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "\n",
        "    def forward(self, input):\n",
        "        inputs, matrix3x3, matrix64x64 = self.pointnet(input)\n",
        "        stack = torch.cat(inputs,1)\n",
        "\n",
        "\n",
        "        \n",
        "        ###########################################################\n",
        "        ################## INSERT YOUR CODE HERE ##################\n",
        "        ###########################################################\n",
        "        output = self.mlp_3_r(self.mlp_128_r(self.mlp_256_r(self.mlp_512_r(stack))))\n",
        "\n",
        "\n",
        "        return self.logsoftmax(output), matrix3x3, matrix64x64\n"
      ],
      "metadata": {
        "id": "NasQpm2azD3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pointNetLoss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n",
        "    criterion = torch.nn.NLLLoss()\n",
        "    bs=outputs.size(0)\n",
        "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n",
        "    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n",
        "    if outputs.is_cuda:\n",
        "        id3x3=id3x3.cuda()\n",
        "        id64x64=id64x64.cuda()\n",
        "    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n",
        "    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n",
        "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)\n"
      ],
      "metadata": {
        "id": "--j7uBZ5zIKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pointnet = PointNetSeg()\n",
        "pointnet.to(device);\n",
        "\n",
        "optimizer = torch.optim.Adam(pointnet.parameters(), lr=0.005)\n",
        "\n",
        "def train(model, train_loader, val_loader=None,  epochs=15, save=True):\n",
        "    best_val_acc = -1.0\n",
        "    for epoch in range(epochs): \n",
        "        pointnet.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device).float()\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, m3x3, m64x64 = pointnet(inputs.transpose(1,2))\n",
        "            loss = pointNetLoss(outputs, labels, m3x3, m64x64)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9 or True:    # print every 10 mini-batches\n",
        "                    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
        "                    running_loss = 0.0\n",
        "\n",
        "        pointnet.eval()\n",
        "        correct = total = 0\n",
        "\n",
        "        # validation\n",
        "        with torch.no_grad():\n",
        "            for data in val_loader:\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device).float()\n",
        "                labels = labels.to(device)\n",
        "                outputs, __, __ = pointnet(inputs.transpose(1,2))\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                \n",
        "                total   += labels.size(0) * labels.size(1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print(\"correct\", correct, \"/\", total)\n",
        "        val_acc = 100.0 * correct / total\n",
        "        print('Valid accuracy: %d %%' % val_acc)\n",
        "\n",
        "        # save the model\n",
        "        if save and val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            path = os.path.join(drive_path, \"MyDrive\", \"pointnetmodel.yml\")\n",
        "            print(\"best_val_acc:\", val_acc, \"saving model at\", path)\n",
        "            torch.save(pointnet.state_dict(), path)\n",
        "\n",
        "train(pointnet, train_loader, val_loader, save=True)"
      ],
      "metadata": {
        "id": "p--arXt-zMZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}